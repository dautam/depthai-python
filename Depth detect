import cv2
import depthai as dai
from itertools import cycle


# Define the DepthAI pipeline
pipeline = dai.Pipeline()

# Initialize the camera
cam_rgb = pipeline.createColorCamera()
cam_rgb.setPreviewSize(300, 300)
cam_rgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)

# Configure the camera properties
cam_rgb.setFps(30)
cam_rgb.setInterleaved(False)
cam_rgb.setColorOrder(dai.ColorCameraProperties.ColorOrder.RGB)

# Define the Neural Network for depth detection
nn_path = 'depth.blob'
nn_shape = dai.Demension((1,3, 300, 300))


model_nn = dai.EdgeDetectionNetwork()
model_nn.setBlobPath(nn_path)
model_nn.setConfidenceThreshold(0.5)
model_nn.setNumThreads(2)
model_nn.input.setBlocking(False)
model_nn.setNumPoolFrames(1)
model_nn.input.setQueueSize(1)
model_nn.input.setShape(nn_shape)

# Define the Neural Network for obstacle detection
obstacle_nn_path = 'obstacle.blob'
obstacle_nn_shape = dai.Dimensions((1, 3, 416, 416))

model_obstacle_nn = dai.Classifier()
model_obstacle_nn.setBlobPath(obstacle_nn_path)
model_obstacle_nn.setNumThreads(2)
model_obstacle_nn.input.setBlocking(False)
model_obstacle_nn.input.setQueueSize(1)
model_obstacle_nn.input.setShape(obstacle_nn_shape)

# Link the camera output to the Neural Networks inputs
cam_rgb.preview.link(model_nn.input)
cam_rgb.preview.link(model_obstacle_nn.input)

# Define the output streams
xout_video = pipeline.createXLinkOut()
xout_video.setStreamName("video")
cam_rgb.preview.link(xout_video.input)

xout_depth = pipeline.createXLinkOut()
xout_depth.setStreamName("depth")
model_nn.passthrough.link(xout_depth.input)

# Connect to the OAK-D device and start the pipeline
with dai.Device(pipeline) as device:

    # Output queues will be used to get the frames from the device
    q_video = device.getOutputQueue(name="video", maxSize=1, blocking=False)
    q_depth = device.getOutputQueue(name="depth", maxSize=1, blocking=False)

    # Create a cycle iterator for the obstacle detection results
    obstacle_results = cycle([False])

    # Continuously get the video and depth frames from the queues and display them
    while True:
        # Get the video frame from the queue and display it
        in_video = q_video.tryGet()
        if in_video is not None:
            video_frame = in_video.getCvFrame()

            # Get the depth frame from the queue
            in_depth = q_depth.tryGet()
            if in_depth is not None:
                depth_frame = in_depth.getFrame()
                depth_data = depth_frame.getData()

                # Get the depth values for the pixels in the center of the image
                center_x = int(depth_frame.getWidth() / 2)
                center_y = int(depth_frame.getHeight() / 2)
                center_index = center_y * depth_frame.getWidth() + center_x
                center_depth = depth_data[center_index]

                # Calculate the distance to the ground and stair steps
                # Assume the distance to the ground is 0 and the height of a stair step is 0.2 meters
                ground_distance = center_depth
                stair_step_distance = ground_distance + 0.2

            # Display the depth values and distances
            cv2.imshow("depth", depth_data)
            print("Ground distance:", ground_distance, "meters")
            print("Stair step distance:", stair_step_distance, "meters")

        if cv2.waitKey(1) == ord('q'):
            break

cv2.destroyAllWindows()
